#!/usr/bin/env python3
"""
Markdown Sync for Memory Bank 2.0
æ—¢å­˜ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã¨çŸ¥è­˜DBã‚’åŒæœŸ

.claude/debug/latest.md â†’ ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’æŠ½å‡º
.claude/context/history.md â†’ æ±ºå®šäº‹é …ã‚’æŠ½å‡º  
.claude/core/current.md â†’ å­¦ç¿’å†…å®¹ã‚’æŠ½å‡º
"""

import sys
import os
import re
import time
import json
from pathlib import Path
from typing import List, Dict, Set

# knowledge_storeãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.dirname(__file__))
from knowledge_store import KnowledgeStore, OptimizedKnowledgeStore

def extract_section(content: str, section_name: str) -> str:
    """ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‹ã‚‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º"""
    # "## ã‚»ã‚¯ã‚·ãƒ§ãƒ³å" ã¾ãŸã¯ "**ã‚»ã‚¯ã‚·ãƒ§ãƒ³å**:" ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
    patterns = [
        rf"##\s*{re.escape(section_name)}.*?\n(.*?)(?=\n##|\n$)",
        rf"\*\*{re.escape(section_name)}\*\*:\s*(.*?)(?=\n\*\*|\n$)"
    ]
    
    for pattern in patterns:
        match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
        if match:
            return match.group(1).strip()
    return ""

def sync_debug_file():
    """debug/latest.mdã‹ã‚‰ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’æŠ½å‡º"""
    debug_file = Path(".claude/debug/latest.md")
    if not debug_file.exists():
        return []
        
    content = debug_file.read_text(encoding='utf-8')
    extracted = []
    
    # å•é¡Œã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º
    problem = extract_section(content, "å•é¡Œ")
    if problem:
        extracted.append({
            "title": "Debug: " + problem.split('\n')[0][:50],
            "content": problem,
            "type": "error",
            "source_file": str(debug_file)
        })
    
    # åŸå› ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º  
    cause = extract_section(content, "åŸå› ")
    if cause:
        extracted.append({
            "title": "Debug Cause: " + cause.split('\n')[0][:50],
            "content": cause,
            "type": "memo",
            "source_file": str(debug_file)
        })
    
    # è§£æ±ºç­–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º
    solution = extract_section(content, "è§£æ±ºç­–")
    if solution:
        extracted.append({
            "title": "Debug Solution: " + solution.split('\n')[0][:50],
            "content": solution,
            "type": "solution",
            "source_file": str(debug_file)
        })
    
    return extracted

def sync_history_file():
    """context/history.mdã‹ã‚‰æ±ºå®šäº‹é …ã‚’æŠ½å‡º"""
    history_file = Path(".claude/context/history.md")
    if not history_file.exists():
        return []
        
    content = history_file.read_text(encoding='utf-8')
    extracted = []
    
    # ADRï¼ˆArchitecture Decision Recordï¼‰ã‚’æŠ½å‡º
    adr_pattern = r"### \[(\d{4}-\d{2}-\d{2})\] (.+?)\n.*?- \*\*æ±ºå®š\*\*:\s*(.+?)\n.*?- \*\*ç†ç”±\*\*:\s*(.+?)\n"
    
    for match in re.finditer(adr_pattern, content, re.DOTALL):
        date = match.group(1)
        title = match.group(2)
        decision = match.group(3)
        reason = match.group(4)
        
        extracted.append({
            "title": f"ADR: {title}",
            "content": f"æ±ºå®š: {decision}\nç†ç”±: {reason}",
            "type": "decision",
            "source_file": str(history_file),
            "tags": ["adr", date]
        })
    
    return extracted

def sync_current_file():
    """core/current.mdã‹ã‚‰å­¦ç¿’å†…å®¹ã‚’æŠ½å‡º"""
    current_file = Path(".claude/core/current.md") 
    if not current_file.exists():
        return []
        
    content = current_file.read_text(encoding='utf-8')
    extracted = []
    
    # å­¦ç¿’å†…å®¹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º
    learning = extract_section(content, "ä»Šé€±å­¦ã‚“ã ã“ã¨")
    if learning:
        # å„å­¦ç¿’é …ç›®ã‚’åˆ†å‰²
        for line in learning.split('\n'):
            if line.strip().startswith('- '):
                item = line.strip()[2:]  # "- "ã‚’é™¤å»
                if ':' in item:
                    tech, effect = item.split(':', 1)
                    extracted.append({
                        "title": f"Learning: {tech.strip()}",
                        "content": effect.strip(),
                        "type": "memo",
                        "source_file": str(current_file),
                        "tags": ["learning"]
                    })
    
    return extracted

def get_file_timestamp(file_path: str) -> float:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—"""
    try:
        return os.path.getmtime(file_path)
    except OSError:
        return 0.0

def get_last_sync_times() -> Dict[str, float]:
    """æœ€çµ‚åŒæœŸæ™‚åˆ»ã‚’å–å¾—"""
    sync_file = Path(".claude/index/.last_sync_times")
    if not sync_file.exists():
        return {}
    
    try:
        with open(sync_file, 'r') as f:
            return json.load(f)
    except (json.JSONDecodeError, FileNotFoundError):
        return {}

def update_sync_times(file_times: Dict[str, float]):
    """æœ€çµ‚åŒæœŸæ™‚åˆ»ã‚’æ›´æ–°"""
    sync_file = Path(".claude/index/.last_sync_times")
    sync_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(sync_file, 'w') as f:
        json.dump(file_times, f, indent=2)

def is_file_changed(file_path: str, last_sync_times: Dict[str, float]) -> bool:
    """ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯"""
    current_time = get_file_timestamp(file_path)
    last_time = last_sync_times.get(file_path, 0.0)
    return current_time > last_time

def sync_file_by_type(file_path: str) -> List[Dict]:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦åŒæœŸå‡¦ç†ã‚’å®Ÿè¡Œ"""
    file_path_obj = Path(file_path)
    
    if file_path_obj.name == "latest.md" and "debug" in file_path:
        return sync_debug_file()
    elif file_path_obj.name == "history.md" and "context" in file_path:
        return sync_history_file()
    elif file_path_obj.name == "current.md" and "core" in file_path:
        return sync_current_file()
    else:
        return []

def sync_incremental(file_paths: List[str] = None) -> int:
    """ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«åŒæœŸï¼ˆå¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼‰"""
    if file_paths is None:
        file_paths = [
            ".claude/debug/latest.md",
            ".claude/context/history.md",
            ".claude/core/current.md"
        ]
    
    last_sync_times = get_last_sync_times()
    changed_files = []
    
    for file_path in file_paths:
        if os.path.exists(file_path) and is_file_changed(file_path, last_sync_times):
            changed_files.append(file_path)
    
    if not changed_files:
        print("ğŸ“ å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“")
        return 0
    
    return sync_batch(changed_files)

def sync_batch(file_paths: List[str]) -> int:
    """ãƒãƒƒãƒå‡¦ç†ï¼ˆè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†ï¼‰"""
    store = OptimizedKnowledgeStore.get_instance(".")
    total_synced = 0
    last_sync_times = get_last_sync_times()
    
    try:
        # ãƒãƒƒãƒå‡¦ç†ç”¨ã®ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆ
        batch_items = []
        
        for file_path in file_paths:
            if not os.path.exists(file_path):
                continue
                
            items = sync_file_by_type(file_path)
            batch_items.extend(items)
            
            # åŒæœŸæ™‚åˆ»ã‚’æ›´æ–°
            last_sync_times[file_path] = get_file_timestamp(file_path)
        
        # ãƒãƒƒãƒå‡¦ç†ã§ä¸€æ‹¬è¿½åŠ 
        if batch_items:
            added_ids = store.add_batch(batch_items, skip_duplicates=True)
            total_synced = len(added_ids)
            
            # çµæœè¡¨ç¤º
            for i, item in enumerate(batch_items):
                if i < len(added_ids):
                    file_name = Path(item["source_file"]).name if item["source_file"] else "unknown"
                    print(f"âœ“ {file_name}åŒæœŸ: {item['title']} (ID: {added_ids[i]})")
        
        # åŒæœŸæ™‚åˆ»ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        update_sync_times(last_sync_times)
        
        if total_synced > 0:
            print(f"\nğŸ‰ ãƒãƒƒãƒåŒæœŸå®Œäº†: {total_synced}ä»¶ã®çŸ¥è­˜ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
        else:
            print("ğŸ“ åŒæœŸå¯¾è±¡ã¨ãªã‚‹æ–°ã—ã„æƒ…å ±ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
    except Exception as e:
        print(f"âŒ åŒæœŸã‚¨ãƒ©ãƒ¼: {e}")
    finally:
        # OptimizedKnowledgeStoreã¯ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãªã®ã§ã€æ˜ç¤ºçš„ã«é–‰ã˜ãªã„
        pass
    
    return total_synced

def sync_smart(file_paths: List[str] = None) -> int:
    """ã‚¹ãƒãƒ¼ãƒˆåŒæœŸï¼ˆé‡è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã€å¤‰æ›´ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰"""
    if file_paths is None:
        # é‡è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¯¾è±¡
        file_paths = [
            ".claude/core/current.md",
            ".claude/core/next.md",
            ".claude/context/history.md",
            ".claude/debug/latest.md"
        ]
    
    return sync_incremental(file_paths)

def sync_all():
    """ã™ã¹ã¦ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒæœŸï¼ˆå¾“æ¥ã®å‹•ä½œï¼‰"""
    file_paths = [
        ".claude/debug/latest.md",
        ".claude/context/history.md",
        ".claude/core/current.md"
    ]
    
    return sync_batch(file_paths)

def sync_with_stats() -> Dict:
    """çµ±è¨ˆæƒ…å ±ä»˜ãã§åŒæœŸå®Ÿè¡Œ"""
    start_time = time.time()
    
    # åŒæœŸå®Ÿè¡Œ
    synced_count = sync_all()
    
    end_time = time.time()
    elapsed = end_time - start_time
    
    # çµ±è¨ˆæƒ…å ±å–å¾—
    store = OptimizedKnowledgeStore.get_instance(".")
    stats = store.get_stats()
    
    return {
        "synced_count": synced_count,
        "elapsed_time": elapsed,
        "total_items": stats["total_items"],
        "by_type": stats["by_type"]
    }

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    if len(sys.argv) > 1:
        action = sys.argv[1]
        
        if action == "debug":
            items = sync_debug_file()
            print(f"DebugæŠ½å‡º: {len(items)}ä»¶")
            for item in items:
                print(f"  - {item['title']}")
                
        elif action == "history":
            items = sync_history_file()
            print(f"HistoryæŠ½å‡º: {len(items)}ä»¶")
            for item in items:
                print(f"  - {item['title']}")
                
        elif action == "current":
            items = sync_current_file()
            print(f"CurrentæŠ½å‡º: {len(items)}ä»¶")
            for item in items:
                print(f"  - {item['title']}")
                
        elif action == "incremental":
            # ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«åŒæœŸ
            file_paths = sys.argv[2:] if len(sys.argv) > 2 else None
            if file_paths:
                # å¼•æ•°ã§æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿
                sync_incremental(file_paths)
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«
                sync_incremental()
                
        elif action == "batch":
            # ãƒãƒƒãƒå‡¦ç†
            file_paths = sys.argv[2:] if len(sys.argv) > 2 else [
                ".claude/debug/latest.md",
                ".claude/context/history.md",
                ".claude/core/current.md"
            ]
            sync_batch(file_paths)
            
        elif action == "smart":
            # ã‚¹ãƒãƒ¼ãƒˆåŒæœŸ
            file_paths = sys.argv[2:] if len(sys.argv) > 2 else None
            sync_smart(file_paths)
            
        elif action == "stats":
            # çµ±è¨ˆæƒ…å ±ä»˜ãåŒæœŸ
            result = sync_with_stats()
            print(f"\nğŸ“Š åŒæœŸçµ±è¨ˆ:")
            print(f"  åŒæœŸä»¶æ•°: {result['synced_count']}ä»¶")
            print(f"  å®Ÿè¡Œæ™‚é–“: {result['elapsed_time']:.2f}ç§’")
            print(f"  ç·ä»¶æ•°: {result['total_items']}ä»¶")
            print(f"  ã‚¿ã‚¤ãƒ—åˆ¥: {result['by_type']}")
            
        elif action == "info":
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±è¡¨ç¤º
            store = OptimizedKnowledgeStore.get_instance(".")
            stats = store.get_stats()
            print(f"\nğŸ“Š Memory Bank æƒ…å ±:")
            print(f"  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {stats['db_path']}")
            print(f"  ç·ä»¶æ•°: {stats['total_items']}ä»¶")
            print(f"  ã‚¿ã‚¤ãƒ—åˆ¥ä»¶æ•°:")
            for type_name, count in stats['by_type'].items():
                print(f"    {type_name}: {count}ä»¶")
            
        else:
            print("Usage: sync_markdown.py [debug|history|current|incremental|batch|smart] [file_paths...]")
            print("")
            print("åŒæœŸãƒ¢ãƒ¼ãƒ‰:")
            print("  incremental - å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿åŒæœŸ")
            print("  batch       - æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬åŒæœŸ")
            print("  smart       - é‡è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¤‰æ›´ãƒã‚§ãƒƒã‚¯ä»˜ãåŒæœŸ")
            print("  stats       - çµ±è¨ˆæƒ…å ±ä»˜ãã§åŒæœŸå®Ÿè¡Œ")
            print("  info        - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±è¡¨ç¤º")
            print("æŠ½å‡ºãƒ¢ãƒ¼ãƒ‰:")
            print("  debug       - ãƒ‡ãƒãƒƒã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿æŠ½å‡º")
            print("  history     - å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿æŠ½å‡º")
            print("  current     - ç¾åœ¨çŠ¶æ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿æŠ½å‡º")
            print("")
            print("å¼•æ•°ãªã—ã§å®Ÿè¡Œã™ã‚‹ã¨å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒæœŸã—ã¾ã™")
    else:
        sync_all()

if __name__ == "__main__":
    main()